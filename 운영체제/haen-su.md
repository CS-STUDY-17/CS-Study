    
# CHAPTER 3 운영체제

## SECTION 1 운영체제와 컴퓨터

### 1. 운영체제란?

- 운영체제(OS, Operating System)는 사용자가 컴퓨터를 쉽게 다룰 수 있도록 해주는 인터페이스
- 하드웨어와 소프트웨어를 관리

### 2. 운영체제의 역할과 구조

(1) 운영체제의 역할

- CPU 스케줄링과 프로세스 관리
- 메모리 관리
- 디스크 파일 관리
- I/O 디바이스 관리

(2) 운영체제의 구조

<img width="364" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/99b03f81-8947-48d8-b486-e526542cc0c5">


- 시스템콜: 운영체제가 커널에 접근하기 위한 인터페이스
    
    ex) 사용자 프로그램이 I/O 요청을 실행할시 시스템콜을 통해 유저모드에서 커널모드로 진입하여 로직 수행 후 다시 유저모드로 복귀
    
    - `modebit`: 시스템콜이 작동될 때 유저모드와 커널모드를 구분하는 bit (0: 커널모드, 1: 유저모드)
    

### 3. 컴퓨터의 요소

<img width="530" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/cffb88e3-ee9e-4071-92d0-c6de29c43bdf">


- **CPU(Central Processing Unit)**: 커널이 프로그램을 메모리에 올려 프로세스로 만들면 메모리에 존재하는 명령어를 해석해서 실행
    - 제어장치(CU, Control Unit): 프로세스 조작을 지시하는 CPU의 부품
        - 입출력 장치 간 통신을 읽고 해석
        - 데이터 처리 순서 결정
    - 레지스터(register): CPU 내부의 매우 빠른 임시 기억장치
    - 산술논리연산장치(ALU, Arithemetic Logic Unit): 산술연산, 논리연산을 처리하는 디지털 회로
    
    <aside>
    📌 CPU의 연산 처리
    
    - 제어장치가 메모리와 레지스터에 계산할 값을 로드
    - 제어장치가 ALU에 레지스터에 있는 값을 계산하라고 명령
    - 제어장치가 레지스터에 저장된 계산된 값을 메모리로 저장
    </aside>
    
    <aside>
    📌 인터럽트: I/O 디바이스, 산술 연산, 프로세스 오류 등으로 인해 CPU가 잠깐 정지되는 것 → 인터럽트가 발생되면 인터럽트 벡터에서 인터럽트 핸들러 함수가 실행됨
    
    - 하드웨어 인터럽트: I/O 디바이스에서 발생하는 인터럽트
    - 소프투웨어 인터럽트(trap): 프로세스 오류 등으로 프로세스가 시스템콜을 호출하는 경우
    </aside>

<br>
<br>

## SECTION 2 메모리

### 1. 메모리 계층

|  | 휘발성 | 용량 | 속도 |
| --- | --- | --- | --- |
| 레지스터 | O | 가장 작음 | 가장 빠름 |
| 캐시(L1, L2 캐시) | O | 작음 | 빠름 |
| 메모리(RAM/주기억장치) | O | 보통 | 보통 |
| 저장장치(HDD, SSD/보조기억장치) | X | 큼 | 느림 |
- RAM은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 필요할 때마다 CPU에 빠르게 전달하는 역할
- 계층 위로 올라갈수록 가격이 비싸짐

### 2. 캐시

(1) 캐시란?

- 데이터를 미리 복사해놓는 임시 저장소
- 빠른 장치와 느린 장치 사이의 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
- 데이터에 접근하는 시간이 오래 걸리는 경우를 해결하고 재계산 하는 시간 절약
- 캐싱 계층: 계층과 계층 사이에 있는 계층(주기억장치는 보조기억장치의 캐싱 계층)

(2) 캐시 설정: 자주 사용하는 데이터 기반으로 캐시를 설정하자 → **지역성**

- **시간 지역성(temporal locality)**: 최근에 사용한 데이터에 다시 접근하려는 특성
- **공간 지역성(spatial locality):** 최근에 사용한 데이터가 위치한 공간과 가까운 공간에 접근하려는 특성

(3) 캐시히트와 캐시미스

- **캐시히트**: 캐시에서 원하는 데이터를 찾았을 때 → 빠름
- **캐시미스**: 캐시에 원하는 데이터가 없을 때 주메모리에서 데이터를 찾아오는 것 → 느림

(4) 캐시매핑: 캐시가 히트되기 위해 매핑하는 방법

- **직접 매핑(directed mapping)**: 메인 메모리와 캐시를 똑같은 크기로 나누고 순서대로 매핑
    
    → 구현이 간단하지만 적중률이 낮고 캐시 교체가 잦아 성능이 낮음
    
    ex) 메인 메모리가 1~100, 캐시가 1~10의 크기만큼 있을 때, 1:1~10, 2:11~20 … 으로 매핑
    
- **연관 매핑(associative mapping)**: 순서를 일치시키지 않고 무작위로 매핑
    
    → 검색은 느리지만 적중률이 높음(검색 속도보다 적중률이 높은 게 성능이 더 좋음)
    
- **집합 연관 매핑(set associative mapping)**: 순서는 일치시키지만 집합을 두어 저장
    
    ex) 메인 메모리가 1~100, 캐시가 1~10의 크기만큼 있을 때, 1~5:1~50, 6~10:51~100 으로 나누어 무작위로 매핑
    

(5) 웹 브라우저의 캐시: 사용자의 정보 등을 웹 브라우저에 저장해놓고 서버의 인증/인가에 사용

- **쿠키**: 만료 기한이 있는 Key-Value 저장소
- **로컬 스토리지**: 만료 기한이 없는 Key-Value 저장소 → 도메인 단위로 저장, 생성
- **세션 스토리지**: 만료 기한이 없는 Key-Value 저장소 → 탭 단위로 저장, 생성

### 3. 메모리 관리

(1) **가상 메모리(virtual memory)**: 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화 하여 사용자들에게 큰 메모리로 보이가 만드는 기법

- MMU: 가상 주소(logical address)를 를 통해 실제 메모리상의 주소(physical address)로 바꾸는 장치
- 페이지 테이블: 가상 주소와 실제 주소가 매핑되어 있고, 프로세스의 주소 정보를 저장
- TLB: 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시 → 페이지 테이블 캐시
- 스와핑(swapping): 메모리에서 사용되지 않는 데이터를 하드 디스크로 내려 보내고 다른 데이터를 불러오는 것
    <img width="459" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/3d8de3ed-a7d6-4fc9-97e3-9243a2b17685">
    1. 메모리 초기 상태. 프로세스 A만 존재
    2. 프로세스 B가 새로 생성 or swap in
    3. 프로세스 C가 새로 생성 or swap in
    4. 프로세스 A가 swap out
    5. 프로세스 D가 새로 생성 or swap in
    6. 프로세스 B가 종료 or swap out
    7. 프로세스 A가 swap in
    
    > swap in: 디스크에 있던 프로세스가 메모리에 적재됨
    > 
    
    > swap out: 메모리에서 실행 중이던 프로세스가 디스크로 적재됨
    > 
    
    > memory compaction: 스와핑 결과 메모리에 여러 개의 분리된 빈 공간(hole)들이 만들어지면 프로세스들의 위치를 이동하여 빈 공간들을 모아 하나의 큰 공간으로 합치는 것
    > 
- 페이지 폴트(Page fault): 가상 주소 공간에 매핑되지 않은 주소를 참조했을 때 CPU가 트랩을 발생시켜 운영체제에게 알리는 것 → 스와핑 발생

(2) **스레싱(thrasing)**: 가용 메모리 공간이 작아 전체 working set을 유지할 수 없어 많은 페이지 폴트가 일어나여 프로세스의 진행이 느려지는 상황

- 프리페이징(prepaging): 프로세스의 working set을 미리 파악하고 프로세스가 시작하기 전에 working set을 메모리에 유지 → 페이지 폴트 줄임
- PFF(Page Fault Frequency): 페이지 폴트 빈도의 상한선과 하한선을 만들어 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄임

(3) 메모리 할당

- 연속 할당: 메모리에 프로세스의 실행 공간을 연속적으로 할당
    - 고정 분할 방식(fixed partition allocation): 메모리를 미리 나누어 관리 → 내부 단편화 발생
    - 가변 분할 방식(variable partition allocation): 프로세스의 크기에 맞게 동적으로 메모리를 나눠 사용
        - first fit
        - best fit
        - worst fit
- 불연속 할당
    - 페이징(paing)
    - 세그멘테이션(segmentation)
    - 페이지드 세그멘테이션(paged segmentation)

(4) 페이지 교체 알고리즘

> page fault가 발생하면 새로 진입할 페이지를 위한 공간을 만들기 위해 이미 존재하고 있는 page 중 하나를 메모리에서 제거해야함 → 어떤 page를 제거할까? → 자주 사용한 page는 제거하지 말자!
> 

- **Optimal Page Replacement Algorithm**: 가장 큰 레이블(참조되는 시간)을 갖는 페이지를 교체
    - 각 페이지들이 미래의 어느 시점에 참조 될지 알 수 없으므로 구현이 불가능 → 실제 구현한 페이지 교체 알고리즘과 성능 비교 용도
    
- **NRU(Not Recently Used):** page table entry의 R bit(read/write)와 M bit(write)에 따라 클래스를 구분하여 페이지를 교체
    - 클래스 0: R bit = 0, M bit 0(참조되지 않았고, 수정되지 않음)
    - 클래스 1: R bit = 0, M bit 1(참조되지 않았고, 수정되었음)
    - 클래스 2: R bit = 1, M bit 0(참조되었고, 수정되지 않음)
    - 클래스 3: R bit = 1, M bit 1(참조되었고, 수정되었음)
    - 클래스 0, 1, 2, 3 순서로 페이지를 교체하며, 만일 같은 클래스 상태의 페이지가 여러 개라면 랜덤 선택
    - 최근에 참조된 페이지와 그렇지 않은 페이지를 구분하기 위하여 주기적으로 R bit를 클리어함
    
- **FIFO(First In First Out):** 운영체제가 현재 메모리에 존재하는 모든 페이지들을 리스트로 관리하며, 가장 과거에 적재된 페이지부터 교체 → 자주 참조되는 페이지를 교체할 가능성 있음

- **Second Chance**: 가장 과거에 적재되었으며, 가장 최근의 clock 간격에 참조되지 않은 페이지를 교체
    - 가장 과거에 적재된 페이지의 R bit가 1이면 리스트의 뒤로 옮기고 R bit를 0으로 클리어, 적재 시간을 현재 시간으로 갱신
    - 가장 과거에 적재된 페이지의 R bit가 0이면 교체
    - 모든 페이지가 참조되었다면 FIFO 알고리즘과 동일하게 작동
    
   <img width="677" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/7e45e66e-4248-4939-80a0-e223277b68d0">

- **NUR(Not Used Recently/The clock)**: 모든 페이지들을 클록 형태의 원형 큐 형태로 관리 → 화살표만 움직이면 되므로 페이지를 직접 이동시키는 Second Chance 알고리즘보다 효율적

  <img width="568" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/aaedfed9-5c98-422b-8424-d9e08225e782">


- **LRU(Least Recently Used)**: 가장 가장 오랫동안 사용되지 않은 페이지를 교체
    - list형태
        - 가장 최근에 참조된 페이지를 리스트의 앞에, 가장 과거에 참조된 페이지를 리스트의 뒤에 위치시킴
        - page fault가 발생하면 가장 뒤에 있는 page를 교체
        - 모든 메모리 참조마다 리스트를 갱신해야함 → 시간과 비용이 큼
    - LRU 하드웨어
        - LRU page
            - C(count)라는 64비트 카운터를 두고 명령어가 실행될 때마다 1씩 증가하게 함
            - 각 페이지 테이블 엔트리는 카운터 값을 저장할 수 있는 공간을 가지고 있음
            - 메모리가 참조될 때마다 참조된 메모리를 담고 있는 페이지를 가리키는 페이지 테이블 엔트리에 C의 값이 저장됨
            - page fualt가 발생하면 모든 페이지 테이블 엔트리의 카운터 값을 조사하여, 가장 적은 값을 갖는 페이지를 교체
        - Matrix
            - 시스템이 n개의 page frame을 가지고 있다면 LRU 하드웨어는 0으로 초기화된 n x n 비트로 구성된 행렬을 가짐
            - page frame k가 참조되면 행렬에서 k 번째 행의 모든 비트를 1로, 열을 0으로 설정
            - page fault가 발생하면 행의 이진 값이 가장 작은 page frame을 교체함
                
               <img width="656" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/7addd53e-5c6c-4a3e-9bb6-50c0348865df">

                
    

- **NFU(Not Frequently Used)**: 각 page마다 0으로 초기화된 소프트웨어 카운터를 유지하고, 가장 적은 카운터 값을 가진 페이지를 교체
    - 클록 인터럽트가 발생할 때마다 운영체제는 메모리의 모든 페이지를 검사하여 R bit 값을 소프트웨어 카운터에 더함
    - 카운터는 각 페이지들이 얼마나 자주 참조되었는지 알려주는 역할
    - Aging: 카운터는 R bit를 더하기 전에 오른쪽으로 1 bit shift하고, R bit는 왼쪽 최상위 비트에 추가됨 → page fault가 발생하면 카운터 값이 가장 적은 페이지가 교체됨
        - LRU 알고리즘과의 차이점
            - LRU 알고리즘은 하드웨어적 구현, NFU 알고리즘은 소프트웨어적 구현
            - NFU 알고리즘은 어떤 page가 더 먼저 참조되었는지 모름
                
                ex) (e)에서 page 3과 5 중에서 어떤 page가 더 먼저 참조 되었는지 모르기 때문에 단순히 값이 작은 page 3을 교체
                
            - 카운트 값이 제한된 비트로 구성 → 과거에 대한 정보 기억을 제한함
                
                <img width="652" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/a7b8d8e8-2a59-42e3-bc79-739c9d8c9a9b">

                

- **The Working Set:** working set에 없는 page를 교체
    - demand paging(요구 페이징): 프로세스가 시작할 때 미리 메모리에 존재하는 페이지는 없으며, 필요할 때 페이지를 적재함
    - locality of reference(참조 지역성): 프로세스가 실행되는 각 단계에서 전체 주소 공간의 일부 페이지들을 집중적으로 참조하는 경향
- **DMA 컨트롤러**: I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- **메모리(RAM)**
- **타이머**: 특정 프로그램에 실행 시간 제한
- **디바이스 컨트롤러**: I/O 디바이스들의 작은 CPU
