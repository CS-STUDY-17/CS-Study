    
# CHAPTER 3 운영체제

## SECTION 1 운영체제와 컴퓨터

### 1. 운영체제란?

- 운영체제(OS, Operating System)는 사용자가 컴퓨터를 쉽게 다룰 수 있도록 해주는 인터페이스
- 하드웨어와 소프트웨어를 관리

### 2. 운영체제의 역할과 구조

(1) 운영체제의 역할

- CPU 스케줄링과 프로세스 관리
- 메모리 관리
- 디스크 파일 관리
- I/O 디바이스 관리

(2) 운영체제의 구조

<img width="364" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/99b03f81-8947-48d8-b486-e526542cc0c5">


- 시스템콜: 운영체제가 커널에 접근하기 위한 인터페이스
    
    ex) 사용자 프로그램이 I/O 요청을 실행할시 시스템콜을 통해 유저모드에서 커널모드로 진입하여 로직 수행 후 다시 유저모드로 복귀
    
    - `modebit`: 시스템콜이 작동될 때 유저모드와 커널모드를 구분하는 bit (0: 커널모드, 1: 유저모드)
    

### 3. 컴퓨터의 요소

<img width="530" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/cffb88e3-ee9e-4071-92d0-c6de29c43bdf">


- **CPU(Central Processing Unit)**: 커널이 프로그램을 메모리에 올려 프로세스로 만들면 메모리에 존재하는 명령어를 해석해서 실행
    - 제어장치(CU, Control Unit): 프로세스 조작을 지시하는 CPU의 부품
        - 입출력 장치 간 통신을 읽고 해석
        - 데이터 처리 순서 결정
    - 레지스터(register): CPU 내부의 매우 빠른 임시 기억장치
    - 산술논리연산장치(ALU, Arithemetic Logic Unit): 산술연산, 논리연산을 처리하는 디지털 회로
    
    <aside>
    📌 CPU의 연산 처리
    
    - 제어장치가 메모리와 레지스터에 계산할 값을 로드
    - 제어장치가 ALU에 레지스터에 있는 값을 계산하라고 명령
    - 제어장치가 레지스터에 저장된 계산된 값을 메모리로 저장
    </aside>
    
    <aside>
    📌 인터럽트: I/O 디바이스, 산술 연산, 프로세스 오류 등으로 인해 CPU가 잠깐 정지되는 것 → 인터럽트가 발생되면 인터럽트 벡터에서 인터럽트 핸들러 함수가 실행됨
    
    - 하드웨어 인터럽트: I/O 디바이스에서 발생하는 인터럽트
    - 소프투웨어 인터럽트(trap): 프로세스 오류 등으로 프로세스가 시스템콜을 호출하는 경우
    </aside>

<br>
<br>

## SECTION 2 메모리

### 1. 메모리 계층

|  | 휘발성 | 용량 | 속도 |
| --- | --- | --- | --- |
| 레지스터 | O | 가장 작음 | 가장 빠름 |
| 캐시(L1, L2 캐시) | O | 작음 | 빠름 |
| 메모리(RAM/주기억장치) | O | 보통 | 보통 |
| 저장장치(HDD, SSD/보조기억장치) | X | 큼 | 느림 |
- RAM은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 필요할 때마다 CPU에 빠르게 전달하는 역할
- 계층 위로 올라갈수록 가격이 비싸짐

### 2. 캐시

(1) 캐시란?

- 데이터를 미리 복사해놓는 임시 저장소
- 빠른 장치와 느린 장치 사이의 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
- 데이터에 접근하는 시간이 오래 걸리는 경우를 해결하고 재계산 하는 시간 절약
- 캐싱 계층: 계층과 계층 사이에 있는 계층(주기억장치는 보조기억장치의 캐싱 계층)

(2) 캐시 설정: 자주 사용하는 데이터 기반으로 캐시를 설정하자 → **지역성**

- **시간 지역성(temporal locality)**: 최근에 사용한 데이터에 다시 접근하려는 특성
- **공간 지역성(spatial locality):** 최근에 사용한 데이터가 위치한 공간과 가까운 공간에 접근하려는 특성

(3) 캐시히트와 캐시미스

- **캐시히트**: 캐시에서 원하는 데이터를 찾았을 때 → 빠름
- **캐시미스**: 캐시에 원하는 데이터가 없을 때 주메모리에서 데이터를 찾아오는 것 → 느림

(4) 캐시매핑: 캐시가 히트되기 위해 매핑하는 방법

- **직접 매핑(directed mapping)**: 메인 메모리와 캐시를 똑같은 크기로 나누고 순서대로 매핑
    
    → 구현이 간단하지만 적중률이 낮고 캐시 교체가 잦아 성능이 낮음
    
    ex) 메인 메모리가 1~100, 캐시가 1~10의 크기만큼 있을 때, 1:1~10, 2:11~20 … 으로 매핑
    
- **연관 매핑(associative mapping)**: 순서를 일치시키지 않고 무작위로 매핑
    
    → 검색은 느리지만 적중률이 높음(검색 속도보다 적중률이 높은 게 성능이 더 좋음)
    
- **집합 연관 매핑(set associative mapping)**: 순서는 일치시키지만 집합을 두어 저장
    
    ex) 메인 메모리가 1~100, 캐시가 1~10의 크기만큼 있을 때, 1~5:1~50, 6~10:51~100 으로 나누어 무작위로 매핑
    

(5) 웹 브라우저의 캐시: 사용자의 정보 등을 웹 브라우저에 저장해놓고 서버의 인증/인가에 사용

- **쿠키**: 만료 기한이 있는 Key-Value 저장소
- **로컬 스토리지**: 만료 기한이 없는 Key-Value 저장소 → 도메인 단위로 저장, 생성
- **세션 스토리지**: 만료 기한이 없는 Key-Value 저장소 → 탭 단위로 저장, 생성

### 3. 메모리 관리

(1) **가상 메모리(virtual memory)**: 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화 하여 사용자들에게 큰 메모리로 보이가 만드는 기법

- MMU: 가상 주소(logical address)를 를 통해 실제 메모리상의 주소(physical address)로 바꾸는 장치
- 페이지 테이블: 가상 주소와 실제 주소가 매핑되어 있고, 프로세스의 주소 정보를 저장
- TLB: 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시 → 페이지 테이블 캐시
- 스와핑(swapping): 메모리에서 사용되지 않는 데이터를 하드 디스크로 내려 보내고 다른 데이터를 불러오는 것
    <img width="459" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/3d8de3ed-a7d6-4fc9-97e3-9243a2b17685">
    1. 메모리 초기 상태. 프로세스 A만 존재
    2. 프로세스 B가 새로 생성 or swap in
    3. 프로세스 C가 새로 생성 or swap in
    4. 프로세스 A가 swap out
    5. 프로세스 D가 새로 생성 or swap in
    6. 프로세스 B가 종료 or swap out
    7. 프로세스 A가 swap in
    
    > swap in: 디스크에 있던 프로세스가 메모리에 적재됨
    > 
    
    > swap out: 메모리에서 실행 중이던 프로세스가 디스크로 적재됨
    > 
    
    > memory compaction: 스와핑 결과 메모리에 여러 개의 분리된 빈 공간(hole)들이 만들어지면 프로세스들의 위치를 이동하여 빈 공간들을 모아 하나의 큰 공간으로 합치는 것
    > 
- 페이지 폴트(Page fault): 가상 주소 공간에 매핑되지 않은 주소를 참조했을 때 CPU가 트랩을 발생시켜 운영체제에게 알리는 것 → 스와핑 발생

(2) **스레싱(thrasing)**: 가용 메모리 공간이 작아 전체 working set을 유지할 수 없어 많은 페이지 폴트가 일어나여 프로세스의 진행이 느려지는 상황

- 프리페이징(prepaging): 프로세스의 working set을 미리 파악하고 프로세스가 시작하기 전에 working set을 메모리에 유지 → 페이지 폴트 줄임
- PFF(Page Fault Frequency): 페이지 폴트 빈도의 상한선과 하한선을 만들어 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄임

(3) 메모리 할당

- 연속 할당: 메모리에 프로세스의 실행 공간을 연속적으로 할당
    - 고정 분할 방식(fixed partition allocation): 메모리를 미리 나누어 관리 → 내부 단편화 발생
    - 가변 분할 방식(variable partition allocation): 프로세스의 크기에 맞게 동적으로 메모리를 나눠 사용
        - first fit
        - best fit
        - worst fit
- 불연속 할당
    - 페이징(paing)
    - 세그멘테이션(segmentation)
    - 페이지드 세그멘테이션(paged segmentation)

(4) 페이지 교체 알고리즘

> page fault가 발생하면 새로 진입할 페이지를 위한 공간을 만들기 위해 이미 존재하고 있는 page 중 하나를 메모리에서 제거해야함 → 어떤 page를 제거할까? → 자주 사용한 page는 제거하지 말자!
> 

- **Optimal Page Replacement Algorithm**: 가장 큰 레이블(참조되는 시간)을 갖는 페이지를 교체
    - 각 페이지들이 미래의 어느 시점에 참조 될지 알 수 없으므로 구현이 불가능 → 실제 구현한 페이지 교체 알고리즘과 성능 비교 용도
    
- **NRU(Not Recently Used):** page table entry의 R bit(read/write)와 M bit(write)에 따라 클래스를 구분하여 페이지를 교체
    - 클래스 0: R bit = 0, M bit 0(참조되지 않았고, 수정되지 않음)
    - 클래스 1: R bit = 0, M bit 1(참조되지 않았고, 수정되었음)
    - 클래스 2: R bit = 1, M bit 0(참조되었고, 수정되지 않음)
    - 클래스 3: R bit = 1, M bit 1(참조되었고, 수정되었음)
    - 클래스 0, 1, 2, 3 순서로 페이지를 교체하며, 만일 같은 클래스 상태의 페이지가 여러 개라면 랜덤 선택
    - 최근에 참조된 페이지와 그렇지 않은 페이지를 구분하기 위하여 주기적으로 R bit를 클리어함
    
- **FIFO(First In First Out):** 운영체제가 현재 메모리에 존재하는 모든 페이지들을 리스트로 관리하며, 가장 과거에 적재된 페이지부터 교체 → 자주 참조되는 페이지를 교체할 가능성 있음

- **Second Chance**: 가장 과거에 적재되었으며, 가장 최근의 clock 간격에 참조되지 않은 페이지를 교체
    - 가장 과거에 적재된 페이지의 R bit가 1이면 리스트의 뒤로 옮기고 R bit를 0으로 클리어, 적재 시간을 현재 시간으로 갱신
    - 가장 과거에 적재된 페이지의 R bit가 0이면 교체
    - 모든 페이지가 참조되었다면 FIFO 알고리즘과 동일하게 작동
    
   <img width="677" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/7e45e66e-4248-4939-80a0-e223277b68d0">

- **NUR(Not Used Recently/The clock)**: 모든 페이지들을 클록 형태의 원형 큐 형태로 관리 → 화살표만 움직이면 되므로 페이지를 직접 이동시키는 Second Chance 알고리즘보다 효율적

  <img width="568" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/aaedfed9-5c98-422b-8424-d9e08225e782">


- **LRU(Least Recently Used)**: 가장 가장 오랫동안 사용되지 않은 페이지를 교체
    - list형태
        - 가장 최근에 참조된 페이지를 리스트의 앞에, 가장 과거에 참조된 페이지를 리스트의 뒤에 위치시킴
        - page fault가 발생하면 가장 뒤에 있는 page를 교체
        - 모든 메모리 참조마다 리스트를 갱신해야함 → 시간과 비용이 큼
    - LRU 하드웨어
        - LRU page
            - C(count)라는 64비트 카운터를 두고 명령어가 실행될 때마다 1씩 증가하게 함
            - 각 페이지 테이블 엔트리는 카운터 값을 저장할 수 있는 공간을 가지고 있음
            - 메모리가 참조될 때마다 참조된 메모리를 담고 있는 페이지를 가리키는 페이지 테이블 엔트리에 C의 값이 저장됨
            - page fualt가 발생하면 모든 페이지 테이블 엔트리의 카운터 값을 조사하여, 가장 적은 값을 갖는 페이지를 교체
        - Matrix
            - 시스템이 n개의 page frame을 가지고 있다면 LRU 하드웨어는 0으로 초기화된 n x n 비트로 구성된 행렬을 가짐
            - page frame k가 참조되면 행렬에서 k 번째 행의 모든 비트를 1로, 열을 0으로 설정
            - page fault가 발생하면 행의 이진 값이 가장 작은 page frame을 교체함
                
               <img width="656" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/7addd53e-5c6c-4a3e-9bb6-50c0348865df">

                
    

- **NFU(Not Frequently Used)**: 각 page마다 0으로 초기화된 소프트웨어 카운터를 유지하고, 가장 적은 카운터 값을 가진 페이지를 교체
    - 클록 인터럽트가 발생할 때마다 운영체제는 메모리의 모든 페이지를 검사하여 R bit 값을 소프트웨어 카운터에 더함
    - 카운터는 각 페이지들이 얼마나 자주 참조되었는지 알려주는 역할
    - Aging: 카운터는 R bit를 더하기 전에 오른쪽으로 1 bit shift하고, R bit는 왼쪽 최상위 비트에 추가됨 → page fault가 발생하면 카운터 값이 가장 적은 페이지가 교체됨
        - LRU 알고리즘과의 차이점
            - LRU 알고리즘은 하드웨어적 구현, NFU 알고리즘은 소프트웨어적 구현
            - NFU 알고리즘은 어떤 page가 더 먼저 참조되었는지 모름
                
                ex) (e)에서 page 3과 5 중에서 어떤 page가 더 먼저 참조 되었는지 모르기 때문에 단순히 값이 작은 page 3을 교체
                
            - 카운트 값이 제한된 비트로 구성 → 과거에 대한 정보 기억을 제한함
                
                <img width="652" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/a7b8d8e8-2a59-42e3-bc79-739c9d8c9a9b">

                

- **The Working Set:** working set에 없는 page를 교체
    - demand paging(요구 페이징): 프로세스가 시작할 때 미리 메모리에 존재하는 페이지는 없으며, 필요할 때 페이지를 적재함
    - locality of reference(참조 지역성): 프로세스가 실행되는 각 단계에서 전체 주소 공간의 일부 페이지들을 집중적으로 참조하는 경향
- **DMA 컨트롤러**: I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
- **메모리(RAM)**
- **타이머**: 특정 프로그램에 실행 시간 제한
- **디바이스 컨트롤러**: I/O 디바이스들의 작은 CPU

<br>
<br>

## SECTION 3 프로세스와 스레드

### 1. 프로세스와 스레드란?

(1) 프로세스

- 프로세스는 컴퓨터에서 실행되고 있는 프로그램
- CPU 스케줄링의 대상이 되는 작업(task)
- 프로그램이 메모리에 올라가 인스턴스화 된 것

(2) 스레드: 프로세스 내 작업의 흐름

### 2. 프로세스와 컴파일 과정(C 언어)

(1) 전처리: 소스코드의 주석을 제거하고 헤더파일을 병합하여 매크로를 치환

(2) 컴파일러: 오류 처리, 코드 최적화 작업을 하여 소스 코드를 어셈블리어로 변환

(3) 어셈블러: 어셈블리어를 목적 코드(object code)로 변환  ex) .c 파일 → .o 파일

(4) 링커: 프로그램 내에 있는 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합하여 실행 파일 생성

<aside>
💡 **정적 라이브러리와 동적 라이브러리**

- 정적 라이브러리: 프로그램 빌드시 라이브러리가 제공하는 모드 코드를 실행 파일에 넣음
- 동적 라이브러리: 프로그램 실행 시 필요할 때만 DLL 이라는 함수 정보를 통해 라이브러리 참조

⇒ 외부 의존도: 정적 라이브러리 < 동적 라이브러리

메모리 효율성: 정적 라이브러리 < 동적 라이브러리

</aside>

### 3. 프로세스의 상태

(1) 생성(create): 프로세스가 생성된 상태, PCB 할당→ fork(), exec()

(2) 대기(ready): CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태

(3) 대기 중단(ready suspended): 대기 상태에서 메모리 부족으로 프로세스가 실행되지 못 하는 상태

(4) 실행(running): CPU 소유권과 메모리를 할당받아 실행 중인 상태

(5) 중단(blocked): 특정 이벤트가 발생하여 프로세스가 차단된 상태

(6) 일시 중단(blocked suspended): 중단된 상태에서 메모리 부족으로 차단된 상태

(7) 종료(terminated): 메모리와 CPU 소유권을 모두 놓고 가는 상태

### 4. 프로세스의 메모리 구조

<img width="376" alt="image" src="https://github.com/CS-STUDY-17/CS-Study/assets/77063375/0503884e-3bb7-4c8e-9b37-cb0183cb0482">


(1) 동적 영역: 스택, 힙 → 런타임 단계에서 메모리를 할당받음

- `malloc()`, `free()`

(2) 정적 영역: 데이터, 텍스트(코드)

### 5. PCB(Process Control Block)

(1) PCB란?

- 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터
- 프로세스가 생성될 될 때 같이 생성됨
- 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리됨

(2) 구조

- 프로세스 스케줄링 상태
- 프로세스 ID
- 프로세스 권한
- 프로그램 카운터
- CPU 레지스터
- CPU 스케줄링 저보
- 계정 저보
- I/O 상태 정보

(3) **컨텍스트 스위칭**: PCB를 기반으로 프로세스의 상태를 저장하고 로드하는 과정

→ 싱글 코어 CPU에서는 어떠한 시점에 실행되고 있는 프로세스는 단 한 개이지만, 아주 빠른 컨텍스트 스위칭을 통해 여러 개의 프로세스가 동시에 실행되고 있는 것처럼 보이게 함

- 유휴 시간(idle time): 컨텍스트 스위칭이 일어날 때 발생하는 CPU가 일을 하지 않는 시간
- 캐시미스: 컨텍스트 스위칭이 일어날 때 프로세스가 가지고 있는 메모리 주소가 바뀌지 않으면 잘못된 주소 변환이 생기므로 캐시 클리어를 하고 이 과정에서 캐시미스 발생

### 6. 멀티프로세싱

(1) 멀티프로세싱이란?

- 멀티 프로세스를 통해 두 가지 이상의 프로세스를 병렬 처리 하는 것
- 프로세스 중 일부에 문제가 발생하더라도 다른 프로세스를 통해 처리 가능하므로 신뢰성 높음

(2) **IPC(Inter Process Communication)**: 프로세스끼리 데이터를 주고 받고 공유 데이터를 관리하는 메커니즘

- 공유 메모리(shared memory)
- 파일
- 소켓
- 익명 파이프(unnamed pipe)
- 명명된 파이프(named pipe)

### 7. 스레드와 멀티스레딩

(1) 스레드: 프로세스의 실행 가능한 가장 작은 단위 → 하나의 프로세스 안에 있는 스레드들은 프로세스의 리소스를 공유함

(2) 멀티스레딩: 프로세스 내 작업을 여러 개의 스레드로 처리

- 장점
    - 한 스레드가 중단 되어도 다른 스레드들은 실행되고 있으므로 프로세스를 중단하지 않고 빠른 처리가 가능하므로 성능이 향상됨
    - 동시성
- 단점: 한 스레드에 문제가 생기면 다른 스레드와 프로세스에 영향을 끼침

### 8. 공유 자원과 임계 영역

(1) **공유 자원(shared resource)**: 시스템 안에서 각 프로세스와 스레드가 접근할 수 있는 자원이나 변수

(2) **경쟁 상태(race condition)**: 두 개 이상의 프로세스가 동시에 공유 자원에 접근을 시도할 때 접근의 타이밍이나 순서등이 결과에 영향을 주는 상태

(3) **임계 영역(critical section)**: 공유 메모리에 접근하는 프로그램 코드 영역

<aside>
💡 critical section 문제를 해결하기 위한 조건

- 상호 배제(mutual exclusion): 한 프로세스가 critical section에 들어갔을 때 다른 프로세스는 들어갈 수 없다
- 한정 대기(bounded waiting): 특정 프로세스가 영원히 critical section에 들어가지 못 하면 안 된다
- 융통성(progress): critical section에 들어간 프로세스가 없다면 외부의 어떤 프로세스든 critical section에 들어갈 수 있으며, 외부의 프로세스는 다른 프로세스를 block 시키면 안 된다
</aside>

- **뮤텍스(mutex)**: unlock과 lock의 상태를 표현하는 객체
    - mutex_lock → critical section → mutex_unlock
- **세마포어(semaphore):** semaphore, P함수, V함수를 통해
    - P함수: semaphore의 값을 검사해 0보다 크면 감소시키고, 0이면 프로세스 중단
    - V함수: down 연산을 완료하지 못 하고 중단된 프로세스가 있다면 무작위로 선택해 P함수 실행, 그렇지 않으면 semaphore 증가
    - P함수 → ciritical section → V함수
- **모니터(monitor)**: 공유자원을 숨기고 해당 접근에 대해 인터페이스만 제공하여 모니터큐를 통해 공유 자원에 대한 작업들을 순차적으로 처리

### 9. 교착 상태(deadlock)

(1) **교착상태**: 두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태

(2) 교착 상태의 원인

- 상호배제: 한 프로세스가 자원을 독점하여 다른 프로세스들이 접근 불가
- 점유 대기: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청
- 비선점: 다른 프로세의 자원을 강제적으로 가져올 수 없음
- 환형 대기: 서로가 서로의 자원을 요구하는 상황

(3) 교착 상태 해결 방법

- 자원을 할당할 때 교착 상태를 피하도록 설계
- 교착 상태 가능성이 없을 때만 자원이 할당되게 설계 → 은행원 알고리즘
- 교착상태를 일으키는 프로세스 삭제
- 프로세스 종료
